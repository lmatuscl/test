{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0czKV2yFYvaZ"
      },
      "source": [
        "# TC 5033\n",
        "## Deep Learning\n",
        "## Fully Connected Deep Neural Networks\n",
        "\n",
        "#### Activity 1b: Implementing a Fully Connected Network for Kaggle ASL Dataset\n",
        "\n",
        "- Objective\n",
        "\n",
        "The aim of this part of the activity is to apply your understanding of Fully Connected Networks by implementing a multilayer network for the [Kaggle ASL (American Sign Language) dataset](https://www.kaggle.com/datasets/grassknoted/asl-alphabet). While you have been provided with a complete solution for a Fully Connected Network using Numpy for the MNIST dataset, you are encouraged to try to come up with the solution.\n",
        "\n",
        "- Instructions\n",
        "\n",
        "    This activity requires submission in teams of 3 or 4 members. Submissions from smaller or larger teams will not be accepted unless prior approval has been granted (only due to exceptional circumstances). While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. Only one person per team needs to submit the completed work, but it is imperative that the names of all team members are listed in a Markdown cell at the very beginning of the notebook (either the first or second cell). Failure to include all team member names will result in the grade being awarded solely to the individual who submitted the assignment, with zero points given to other team members (no exceptions will be made to this rule).\n",
        "\n",
        "    Load and Preprocess Data: You are provided a starter code to load the data. Be sure to understand the code.\n",
        "\n",
        "    Review MNIST Notebook (Optional): Before diving into this activity, you have the option to revisit the MNIST example to refresh your understanding of how to build a Fully Connected Network using Numpy.\n",
        "\n",
        "    Start Fresh: Although you can refer to the MNIST solution at any point, try to implement the network for the ASL dataset on your own. This will reinforce your learning and understanding of the architecture and mathematics involved.\n",
        "\n",
        "    Implement Forward and Backward Pass: Write the code to perform the forward and backward passes, keeping in mind the specific challenges and characteristics of the ASL dataset.\n",
        "    \n",
        "     Design the Network: Create the architecture of the Fully Connected Network tailored for the ASL dataset. Choose the number of hidden layers, neurons, and hyperparameters judiciously.\n",
        "\n",
        "    Train the Model: Execute the training loop, ensuring to track performance metrics such as loss and accuracy.\n",
        "\n",
        "    Analyze and Document: Use Markdown cells to document in detail the choices you made in terms of architecture and hyperparameters, you may use figures, equations, etc to aid in your explanations. Include any metrics that help justify these choices and discuss the model's performance.  \n",
        "\n",
        "- Evaluation Criteria\n",
        "\n",
        "    - Code Readability and Comments\n",
        "    - Appropriateness of chosen architecture and hyperparameters for the ASL dataset\n",
        "    - Performance of the model on the ASL dataset (at least 70% acc)\n",
        "    - Quality of Markdown documentation\n",
        "\n",
        "- Submission\n",
        "\n",
        "Submit this Jupyter Notebook in canvas with your complete solution, ensuring your code is well-commented and includes Markdown cells that explain your design choices, results, and any challenges you encountered.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "j4l0d5RvYvaa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import string\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import os\n",
        "\n",
        "# These lines cause the 'imp' error in Colab's Python 3.12\n",
        "# %load_ext autoreload\n",
        "# %autoreload 2\n",
        "\n",
        "#################################\n",
        "%matplotlib inline\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "VJOeal_AYvaa"
      },
      "outputs": [],
      "source": [
        "\n",
        "DATA_PATH = '/content/sample_data/'\n",
        "train_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_train.csv'))\n",
        "valid_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_valid.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "C3L6qZPLYvaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "14b4f2db-fbe7-4c49-a99b-e0b8de7bf8f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0      3     107     118     127     134     139     143     146     150   \n",
              "1      6     155     157     156     156     156     157     156     158   \n",
              "2      2     187     188     188     187     187     186     187     188   \n",
              "3      2     211     211     212     212     211     210     211     210   \n",
              "4     12     164     167     170     172     176     179     180     184   \n",
              "\n",
              "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0     153  ...       207       207       207       207       206       206   \n",
              "1     158  ...        69       149       128        87        94       163   \n",
              "2     187  ...       202       201       200       199       198       199   \n",
              "3     210  ...       235       234       233       231       230       226   \n",
              "4     185  ...        92       105       105       108       133       163   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0       206       204       203       202  \n",
              "1       175       103       135       149  \n",
              "2       198       195       194       195  \n",
              "3       225       222       229       163  \n",
              "4       157       163       164       179  \n",
              "\n",
              "[5 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8772e1b6-7df7-4d34-8c10-695057a5b337\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>107</td>\n",
              "      <td>118</td>\n",
              "      <td>127</td>\n",
              "      <td>134</td>\n",
              "      <td>139</td>\n",
              "      <td>143</td>\n",
              "      <td>146</td>\n",
              "      <td>150</td>\n",
              "      <td>153</td>\n",
              "      <td>...</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>155</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>158</td>\n",
              "      <td>158</td>\n",
              "      <td>...</td>\n",
              "      <td>69</td>\n",
              "      <td>149</td>\n",
              "      <td>128</td>\n",
              "      <td>87</td>\n",
              "      <td>94</td>\n",
              "      <td>163</td>\n",
              "      <td>175</td>\n",
              "      <td>103</td>\n",
              "      <td>135</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>187</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>...</td>\n",
              "      <td>202</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>210</td>\n",
              "      <td>...</td>\n",
              "      <td>235</td>\n",
              "      <td>234</td>\n",
              "      <td>233</td>\n",
              "      <td>231</td>\n",
              "      <td>230</td>\n",
              "      <td>226</td>\n",
              "      <td>225</td>\n",
              "      <td>222</td>\n",
              "      <td>229</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12</td>\n",
              "      <td>164</td>\n",
              "      <td>167</td>\n",
              "      <td>170</td>\n",
              "      <td>172</td>\n",
              "      <td>176</td>\n",
              "      <td>179</td>\n",
              "      <td>180</td>\n",
              "      <td>184</td>\n",
              "      <td>185</td>\n",
              "      <td>...</td>\n",
              "      <td>92</td>\n",
              "      <td>105</td>\n",
              "      <td>105</td>\n",
              "      <td>108</td>\n",
              "      <td>133</td>\n",
              "      <td>163</td>\n",
              "      <td>157</td>\n",
              "      <td>163</td>\n",
              "      <td>164</td>\n",
              "      <td>179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8772e1b6-7df7-4d34-8c10-695057a5b337')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8772e1b6-7df7-4d34-8c10-695057a5b337 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8772e1b6-7df7-4d34-8c10-695057a5b337');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFxEdTnAYvaa"
      },
      "source": [
        "### Importar Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "YHPc1bNxYvaa"
      },
      "outputs": [],
      "source": [
        "y_train = np.array(train_df['label'])\n",
        "y_val = np.array(valid_df['label'])\n",
        "del train_df['label']\n",
        "del valid_df['label']\n",
        "x_train = train_df.values.astype(np.float32)\n",
        "x_val = valid_df.values.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "code_folding": [],
        "id": "I4trQtfHYvaa"
      },
      "outputs": [],
      "source": [
        "def split_val_test(x, y, pct=0.5, shuffle=True):\n",
        "\n",
        "    # Ensure the number of samples match\n",
        "    assert x.shape[0] == y.shape[0], 'Error: x and y must have the same number of samples'\n",
        "\n",
        "    total_samples = x.shape[0]\n",
        "\n",
        "    if shuffle:\n",
        "        # Create randomized indices\n",
        "        indices = np.random.permutation(total_samples)\n",
        "        x = x[indices]\n",
        "        y = y[indices]\n",
        "\n",
        "    # Calculate the split point\n",
        "    split_idx = int(total_samples * (1 - pct))\n",
        "\n",
        "    # Slice the arrays\n",
        "    x_val, x_test = x[:split_idx], x[split_idx:]\n",
        "    y_val, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "    return x_val, y_val, x_test, y_test\n",
        "\n",
        "# --- CALL THE FUNCTION ---\n",
        "# Make sure this part is NOT indented (it should be at the very left)\n",
        "#x_val, y_val, x_test, y_test = split_val_test(x_val, y_val, pct=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "zw5EpMVrYvaa"
      },
      "outputs": [],
      "source": [
        "x_val, y_val, x_test, y_test = split_val_test(x_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "qJsXkFYtYvaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7882fe1-bea1-470a-95a5-c353c2c05b57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n"
          ]
        }
      ],
      "source": [
        "### The following\n",
        "\n",
        "alphabet=list(string.ascii_lowercase)\n",
        "alphabet.remove('j')\n",
        "alphabet.remove('z')\n",
        "print(len(alphabet))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the original alphabet has 26 letters, and we removed 'j' and 'z', we are left with 24 hand signs to classify."
      ],
      "metadata": {
        "id": "QhJahgZgoQGp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghqCzmc-Yvab"
      },
      "source": [
        "### Normalise"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Calculate the mean and standard deviation from the TRAINING set only\n",
        "asl_mu = x_train.mean()\n",
        "asl_std = x_train.std()\n",
        "\n",
        "# 2. Apply the normalization to all three sets using the training stats\n",
        "x_train = (x_train - asl_mu) / asl_std\n",
        "x_val = (x_val - asl_mu) / asl_std\n",
        "x_test = (x_test - asl_mu) / asl_std\n",
        "\n",
        "print(f\"Normalization complete.\")\n",
        "print(f\"Training Mean: {x_train.mean():.4f} (Should be 0)\")\n",
        "print(f\"Training Std: {x_train.std():.4f} (Should be 1)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4nqy8R4if-g",
        "outputId": "e1c8d5f7-9fbb-4287-f090-7120a792b257"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalization complete.\n",
            "Training Mean: 0.0000 (Should be 0)\n",
            "Training Std: 1.0000 (Should be 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSirjecRYvab"
      },
      "source": [
        "### Graficar muestras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the plotting function\n",
        "def plot_asl(image):\n",
        "    plt.figure(figsize=(5,5))\n",
        "    # .reshape(28, 28) turns the flat 784 pixels back into a square image.\n",
        "    # .squeeze() removes any extra dimensions.\n",
        "    plt.imshow(image.reshape(28, 28).squeeze(), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# 2. Setup the alphabet for readable labels\n",
        "# (Make sure you have run the alphabet.remove lines earlier)\n",
        "alphabet = list(string.ascii_lowercase)\n",
        "if 'j' in alphabet: alphabet.remove('j')\n",
        "if 'z' in alphabet: alphabet.remove('z')\n",
        "\n",
        "# 3. Pick a random sample and display it\n",
        "rnd_idx = np.random.randint(len(y_test))\n",
        "label_idx = int(y_test[rnd_idx])\n",
        "\n",
        "# Map the index to the actual letter\n",
        "letter = alphabet[label_idx] if label_idx < len(alphabet) else \"Unknown\"\n",
        "\n",
        "print(f'La imagen muestreada representa la letra: {letter} (índice {label_idx})')\n",
        "plot_asl(x_test[rnd_idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "mzbMe4NdjNXT",
        "outputId": "68fe7fde-bad0-4f4e-8b88-272903b24a33"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La imagen muestreada representa la letra: p (índice 14)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Arlu9qHYvab"
      },
      "source": [
        "### Ecuaciones para nuestro modelo\n",
        "\n",
        "\n",
        "$$z^1 = W^1 X + b^1$$\n",
        "\n",
        "$$a^1 = ReLU(z^1) $$\n",
        "\n",
        "$$z^2 = W^2 a^1 + b^2$$\n",
        "\n",
        "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
        "\n",
        "\n",
        "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
        "\n",
        "\n",
        "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq9q9gcbYvab"
      },
      "source": [
        "### Funciones adicionales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y4N7o0OYvab"
      },
      "source": [
        "#### Mini batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "u-YqoQ0SYvab"
      },
      "outputs": [],
      "source": [
        "def create_minibatches(mb_size, x, y, shuffle=True):\n",
        "\n",
        "    # sanity check\n",
        "    assert x.shape[0] == y.shape[0], 'Error: x and y must have the same number of samples'\n",
        "\n",
        "    total_data = x.shape[0]\n",
        "\n",
        "    if shuffle:\n",
        "        # Create a list of indices and shuffle them\n",
        "        idxs = np.arange(total_data)\n",
        "        np.random.shuffle(idxs)\n",
        "        # Reorder the data based on the shuffled indices\n",
        "        x = x[idxs]\n",
        "        y = y[idxs]\n",
        "\n",
        "    # Return a generator that yields slices of the data\n",
        "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmcfcuJGYvab"
      },
      "source": [
        "## Nuestra clase Linear, ReLU y Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the class\n",
        "class np_tensor(np.ndarray): pass\n",
        "\n",
        "# 2. Cast ASL datasets to np_tensor\n",
        "# This allows the model to attach gradients to them during the backward pass.\n",
        "x_train = x_train.view(np_tensor)\n",
        "x_val = x_val.view(np_tensor)\n",
        "x_test = x_test.view(np_tensor)\n",
        "\n",
        "# 3. Verify\n",
        "print(type(x_train)) # Should show <class '__main__.np_tensor'>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGnso26Le33P",
        "outputId": "663923c3-7cf0-42dd-f4c0-4769747767c4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.np_tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XloD1fU7Yvab"
      },
      "source": [
        "###  Clase Linear"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear():\n",
        "    def __init__(self, input_size, output_size):\n",
        "\n",
        "        # Kaiming He Initialization:\n",
        "        # We scale the random weights to prevent the signal from vanishing or exploding.\n",
        "        # .view(np_tensor) ensures these weights are treated as our custom tensor type.\n",
        "        self.W = (np.random.randn(output_size, input_size) / np.sqrt(input_size/2)).view(np_tensor)\n",
        "\n",
        "        # Bias Initialization:\n",
        "        # Initialized to zeros as a column vector.\n",
        "        self.b = (np.zeros((output_size, 1))).view(np_tensor)\n",
        "\n",
        "    def __call__(self, X):\n",
        "        '''\n",
        "        FORWARD PASS: Z = W @ X + b\n",
        "        This calculates the weighted sum of the inputs.\n",
        "        '''\n",
        "        # The '@' operator performs matrix multiplication.\n",
        "        # This transforms the input X into the output Z.\n",
        "        Z = self.W @ X + self.b\n",
        "        return Z\n",
        "\n",
        "    def backward(self, X, Z):\n",
        "\n",
        "        # 1. Gradient with respect to the Input (X):\n",
        "        # This is passed back to the previous layer in the network.\n",
        "        X.grad = self.W.T @ Z.grad\n",
        "\n",
        "        # 2. Gradient with respect to the Weights (W):\n",
        "        # This is used to update the weights during the learning step.\n",
        "        self.W.grad = Z.grad @ X.T\n",
        "\n",
        "        # 3. Gradient with respect to the Bias (b):\n",
        "        # We sum the gradients across the batch (axis=1) because the\n",
        "        # bias is shared by all samples in the mini-batch.\n",
        "        self.b.grad = np.sum(Z.grad, axis = 1, keepdims=True)"
      ],
      "metadata": {
        "id": "9iwAlkiweksD"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONlAD424Yvab"
      },
      "source": [
        "### Clase ReLU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU():\n",
        "    def __call__(self, Z):\n",
        "\n",
        "        return np.maximum(0, Z)\n",
        "\n",
        "    def backward(self, Z, A):\n",
        "\n",
        "        # 1. Start by copying the gradient coming from the next layer (A.grad).\n",
        "        Z.grad = A.grad.copy()\n",
        "\n",
        "        # 2. Apply the derivative of ReLU:\n",
        "        # For any position where the original input (Z) was 0 or less,\n",
        "        # the gradient is set to 0. This \"shuts off\" the error flow\n",
        "        # for neurons that were not active.\n",
        "        Z.grad[Z <= 0] = 0"
      ],
      "metadata": {
        "id": "qp6Su2zxgeMW"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-fPY1oDYvab"
      },
      "source": [
        "### Clase Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Sequential_layers():\n",
        "    def __init__(self, layers):\n",
        "\n",
        "        self.layers = layers\n",
        "        self.x = None\n",
        "        # self.outputs: A dictionary to store the result of every layer.\n",
        "        # Backpropagation needs the 'forward' values to calculate the gradients.\n",
        "        self.outputs = {}\n",
        "\n",
        "    def __call__(self, X):\n",
        "\n",
        "        self.x = X\n",
        "        self.outputs['l0'] = self.x # Store the raw input as 'layer 0'\n",
        "\n",
        "        for i, layer in enumerate(self.layers, 1):\n",
        "            # Pass the data through the current layer\n",
        "            self.x = layer(self.x)\n",
        "            # Save the output of this layer (e.g., 'l1', 'l2') for backprop\n",
        "            self.outputs['l'+str(i)] = self.x\n",
        "        return self.x\n",
        "\n",
        "    def backward(self):\n",
        "\n",
        "        # We iterate in REVERSE because the error flows from the\n",
        "        # output back to the input.\n",
        "        for i in reversed(range(len(self.layers))):\n",
        "\n",
        "            self.layers[i].backward(self.outputs['l'+str(i)], self.outputs['l'+str(i+1)])\n",
        "\n",
        "    def update(self, learning_rate = 1e-3):\n",
        "\n",
        "        for layer in self.layers:\n",
        "            # ReLU layers don't have weights or biases, so we skip them.\n",
        "            if isinstance(layer, ReLU): continue\n",
        "\n",
        "            # Standard Gradient Descent formula: W = W - (lr * gradient)\n",
        "            layer.W = layer.W - learning_rate * layer.W.grad\n",
        "            layer.b = layer.b - learning_rate * layer.b.grad\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        return np.argmax(self.__call__(X), axis=0)"
      ],
      "metadata": {
        "id": "_PkcWFLAgm6W"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATYHH38_Yvab"
      },
      "source": [
        "### Cost Function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmaxXEntropy(x, y):\n",
        "\n",
        "    # Get the number of samples in the current batch\n",
        "    batch_size = x.shape[1]\n",
        "\n",
        "    # --- SOFTMAX STEP (Numerical Stability) ---\n",
        "    # We subtract the maximum value from each column to prevent\n",
        "    # np.exp() from producing 'Infinity' (overflow).\n",
        "    exp_scores = np.exp(x - np.max(x, axis=0, keepdims=True))\n",
        "\n",
        "    # Turn scores into probabilities (0 to 1) that sum to 100%\n",
        "    probs = exp_scores / exp_scores.sum(axis=0, keepdims=True)\n",
        "    preds = probs.copy()\n",
        "\n",
        "    # --- COST (LOSS) CALCULATION ---\n",
        "    # Advanced indexing: Pick the probability assigned to the CORRECT class\n",
        "    # y.squeeze() turns the labels into a 1D array for indexing.\n",
        "    y_hat = probs[y.squeeze(), np.arange(batch_size)]\n",
        "\n",
        "    # Calculate Cross-Entropy Loss: -ln(probability of correct class)\n",
        "    # We add a tiny number (1e-8) to avoid log(0) errors.\n",
        "    cost = np.sum(-np.log(y_hat + 1e-8)) / batch_size\n",
        "\n",
        "    # --- GRADIENT CALCULATION (The Shortcut) ---\n",
        "    # The derivative of Cross-Entropy + Softmax is simply (Predictions - Actual).\n",
        "    # We subtract 1 from the probability of the correct class for every sample.\n",
        "    probs[y.squeeze(), np.arange(batch_size)] -= 1\n",
        "\n",
        "    # Store the result in x.grad to start the Backpropagation process.\n",
        "    # We divide by batch_size to keep the gradients at a consistent scale.\n",
        "    x.grad = probs / batch_size\n",
        "\n",
        "    return preds, cost"
      ],
      "metadata": {
        "id": "wGQN-1SngssY"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF0iinQqYvab"
      },
      "source": [
        "### Loop de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(x, y, mb_size):\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # Use mini-batches to avoid memory issues during evaluation\n",
        "    for i, (x_batch, y_batch) in enumerate(create_minibatches(mb_size, x, y)):\n",
        "        # Forward pass: x_batch.T converts (batch, 784) to (784, batch)\n",
        "        pred = model(x_batch.T.view(np_tensor))\n",
        "        # Compare the index of the highest score with the actual label\n",
        "        correct += np.sum(np.argmax(pred, axis=0) == y_batch.squeeze())\n",
        "        total += pred.shape[1]\n",
        "    return correct / total\n",
        "\n",
        "def train(model, epochs, mb_size=128, learning_rate = 1e-3):\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # 1. Iterate through the training data in mini-batches\n",
        "        for i, (x_batch, y_batch) in enumerate(create_minibatches(mb_size, x_train, y_train)):\n",
        "\n",
        "            # 2. FORWARD PASS\n",
        "            # We transpose the batch (.T) because our Linear layer expects (784, batch_size)\n",
        "            scores = model(x_batch.T.view(np_tensor))\n",
        "\n",
        "            # 3. CALCULATE LOSS & INITIAL GRADIENT\n",
        "            # This function returns the probabilities and the average error (cost)\n",
        "            _, cost = softmaxXEntropy(scores, y_batch)\n",
        "\n",
        "            # 4. BACKWARD PASS\n",
        "            # This calculates the gradients for every weight and bias in the model\n",
        "            model.backward()\n",
        "\n",
        "            # 5. UPDATE PARAMETERS\n",
        "            # Adjust weights using Gradient Descent: W = W - (lr * gradient)\n",
        "            model.update(learning_rate)\n",
        "\n",
        "        # 6. EVALUATE PROGRESS\n",
        "        # After each epoch, check the accuracy on the validation set\n",
        "        val_acc = accuracy(x_val, y_val, mb_size)\n",
        "        print(f'Epoch {epoch+1}/{epochs} - Cost: {cost:.4f}, Val Accuracy: {val_acc:.4f}')"
      ],
      "metadata": {
        "id": "DB7ECPAjg6I2"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCVoLHfIYvab"
      },
      "source": [
        "### Create your model and train it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "6GI7oYzwYvab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80bb72a0-e867-46ec-af29-6bd60b67d3df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40 - Cost: 2.5644, Val Accuracy: 0.2273\n",
            "Epoch 2/40 - Cost: 2.1627, Val Accuracy: 0.3717\n",
            "Epoch 3/40 - Cost: 1.6415, Val Accuracy: 0.4428\n",
            "Epoch 4/40 - Cost: 1.4400, Val Accuracy: 0.4894\n",
            "Epoch 5/40 - Cost: 1.1710, Val Accuracy: 0.5100\n",
            "Epoch 6/40 - Cost: 1.0561, Val Accuracy: 0.5368\n",
            "Epoch 7/40 - Cost: 1.0576, Val Accuracy: 0.5547\n",
            "Epoch 8/40 - Cost: 0.9049, Val Accuracy: 0.5703\n",
            "Epoch 9/40 - Cost: 0.8103, Val Accuracy: 0.5856\n",
            "Epoch 10/40 - Cost: 0.9904, Val Accuracy: 0.5970\n",
            "Epoch 11/40 - Cost: 0.7259, Val Accuracy: 0.6068\n",
            "Epoch 12/40 - Cost: 0.5762, Val Accuracy: 0.6180\n",
            "Epoch 13/40 - Cost: 0.6031, Val Accuracy: 0.6316\n",
            "Epoch 14/40 - Cost: 0.5515, Val Accuracy: 0.6425\n",
            "Epoch 15/40 - Cost: 0.6730, Val Accuracy: 0.6545\n",
            "Epoch 16/40 - Cost: 0.5000, Val Accuracy: 0.6651\n",
            "Epoch 17/40 - Cost: 0.5334, Val Accuracy: 0.6771\n",
            "Epoch 18/40 - Cost: 0.5495, Val Accuracy: 0.6799\n",
            "Epoch 19/40 - Cost: 0.5410, Val Accuracy: 0.6863\n",
            "Epoch 20/40 - Cost: 0.3305, Val Accuracy: 0.6935\n",
            "Epoch 21/40 - Cost: 0.5017, Val Accuracy: 0.6969\n",
            "Epoch 22/40 - Cost: 0.3434, Val Accuracy: 0.6974\n",
            "Epoch 23/40 - Cost: 0.3442, Val Accuracy: 0.7025\n",
            "Epoch 24/40 - Cost: 0.3032, Val Accuracy: 0.7069\n",
            "Epoch 25/40 - Cost: 0.2959, Val Accuracy: 0.7083\n",
            "Epoch 26/40 - Cost: 0.2841, Val Accuracy: 0.7097\n",
            "Epoch 27/40 - Cost: 0.2174, Val Accuracy: 0.7136\n",
            "Epoch 28/40 - Cost: 0.2235, Val Accuracy: 0.7167\n",
            "Epoch 29/40 - Cost: 0.2182, Val Accuracy: 0.7197\n",
            "Epoch 30/40 - Cost: 0.1854, Val Accuracy: 0.7250\n",
            "Epoch 31/40 - Cost: 0.1859, Val Accuracy: 0.7270\n",
            "Epoch 32/40 - Cost: 0.2201, Val Accuracy: 0.7301\n",
            "Epoch 33/40 - Cost: 0.2060, Val Accuracy: 0.7292\n",
            "Epoch 34/40 - Cost: 0.1761, Val Accuracy: 0.7301\n",
            "Epoch 35/40 - Cost: 0.1648, Val Accuracy: 0.7306\n",
            "Epoch 36/40 - Cost: 0.1427, Val Accuracy: 0.7326\n",
            "Epoch 37/40 - Cost: 0.2049, Val Accuracy: 0.7365\n",
            "Epoch 38/40 - Cost: 0.1807, Val Accuracy: 0.7379\n",
            "Epoch 39/40 - Cost: 0.1171, Val Accuracy: 0.7351\n",
            "Epoch 40/40 - Cost: 0.1717, Val Accuracy: 0.7368\n"
          ]
        }
      ],
      "source": [
        "# Define the ASL model: 784 inputs, two hidden layers, 25 outputs\n",
        "model = Sequential_layers([\n",
        "    Linear(784, 1024),\n",
        "    ReLU(),\n",
        "    Linear(1024, 512),\n",
        "    ReLU(),\n",
        "    Linear(512, 25)\n",
        "])\n",
        "\n",
        "# Set hyperparameters and start training\n",
        "train(model, epochs=40, mb_size=128, learning_rate=1e-3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After normalizing the data and defining our architecture, we selected the following hyperparameters to optimize the learning process:\n",
        "\n",
        "\n",
        "1. Epochs: 40\n",
        "\n",
        "Why? The ASL dataset (hand shapes) is more complex than MNIST (digits). We increased the epochs from 20 to 40 to give the network more time to adjust its weights. This ensures the model moves past the initial \"confusion\" and begins to distinguish between similar-looking letters like 'm', 'n', and 's'.\n",
        "\n",
        "2. Mini-Batch Size (mb_size): 128\n",
        "\n",
        "Why? 128 is a \"sweet spot\" for hardware efficiency. It is a power of 2, which allows NumPy to perform vectorized matrix math faster.\n",
        "Stability: It is large enough to provide a stable average gradient (preventing the cost from jumping erratically) but small enough to introduce a bit of \"noise\" that helps the model generalize better to the validation set.\n",
        "\n",
        "3. Learning Rate (learning_rate): 1e-3 (0.001)\n",
        "\n",
        "Why? Since we normalized our data (Mean 0, Std 1), a learning rate of 1e-3 is the standard starting point.\n",
        "Balance: It is 10 times faster than our initial 1e-4 attempt. This allows the model to descend the \"loss valley\" quickly without being so large that it causes the gradients to explode or result in nan values."
      ],
      "metadata": {
        "id": "9uZi5wl5QhPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the mini-batch size (128 is a standard choice for this dataset)\n",
        "mb_size = 128\n",
        "\n",
        "# Now we run the accuracy function using the defined mb_size\n",
        "test_acc = accuracy(x_test, y_test, mb_size)\n",
        "\n",
        "print(f\"Final ASL Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lw6YiU61hSeq",
        "outputId": "e06bf636-5383-494b-daef-54ec883bc4be"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final ASL Test Accuracy: 0.7401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we reached the enough % required for the homework"
      ],
      "metadata": {
        "id": "N0DtI_bzrZ2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_number(image):\n",
        "    # Create a figure with a specific size\n",
        "    plt.figure(figsize=(5,5))\n",
        "\n",
        "    # Display the image. .squeeze() removes any extra dimensions\n",
        "    # (like turning (28, 28, 1) into (28, 28))\n",
        "    plt.imshow(image.squeeze(), cmap='gray')\n",
        "\n",
        "    # Hide the axis numbers\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Xgd5dEoUlEoS"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A8qdaFRYvab"
      },
      "source": [
        "### Test your model on Random data from your test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "YQiozQc6Yvab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "53365865-c705-4636-f70c-a22f93667a1a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El valor predicho es: k, el valor real es: k\n"
          ]
        }
      ],
      "source": [
        "idx = np.random.randint(len(y_test))\n",
        "plot_number(x_test[idx].reshape(28,28))\n",
        "\n",
        "# Get the prediction\n",
        "pred = model.predict(x_test[idx].reshape(-1, 1))\n",
        "\n",
        "# Use .item() to get the scalar value and avoid the DeprecationWarning\n",
        "predicted_idx = pred.item()\n",
        "actual_idx = y_test[idx].item()\n",
        "\n",
        "# Map to alphabet\n",
        "predicted_letter = alphabet[predicted_idx]\n",
        "actual_letter = alphabet[actual_idx]\n",
        "\n",
        "print(f'El valor predicho es: {predicted_letter}, el valor real es: {actual_letter}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we successfully built a complete multilayer neural network from scratch using NumPy to classify ASL hand signs, reaching a final test accuracy of 74.01%. We mastered the end-to-end data pipeline, specifically solving the \"exploding gradient\" problem through data normalization and implementing the core mechanics of backpropagation via the Chain Rule. By optimizing hyperparameters like the learning rate and mini-batch size, we demonstrated that a foundational Fully Connected Network can effectively generalize to complex, unseen image data, providing a deep understanding of deep learning logic without the need for high-level frameworks."
      ],
      "metadata": {
        "id": "LDtPLaXDQ3kQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Ksvm-TN9Yvab"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}